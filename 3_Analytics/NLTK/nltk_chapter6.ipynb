{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,random\n",
    "#function returning the last letter of a word\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names# set of male and female names:how to do our own sets?\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6355\n",
      "1589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = train_test_split(featuresets, shuffle=True,test_size=.2)\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7595972309628697\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)# we need other steps like feauture selection etc...\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(gender_features('Alan')))\n",
    "print(classifier.classify(gender_features('Stacey')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     38.0 : 1.0\n",
      "             last_letter = 'a'            female : male   =     35.8 : 1.0\n",
      "             last_letter = 'f'              male : female =     19.6 : 1.0\n",
      "             last_letter = 'v'              male : female =     16.2 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set, test_set = train_test_split(labeled_names, shuffle=True,test_size=.2)\n",
    "train_set = apply_features(gender_features, train_set)\n",
    "test_set = apply_features(gender_features, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Choosing the Right Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count(a)': 1,\n",
       " 'count(b)': 0,\n",
       " 'count(c)': 0,\n",
       " 'count(d)': 0,\n",
       " 'count(e)': 1,\n",
       " 'count(f)': 0,\n",
       " 'count(g)': 0,\n",
       " 'count(h)': 0,\n",
       " 'count(i)': 0,\n",
       " 'count(j)': 0,\n",
       " 'count(k)': 0,\n",
       " 'count(l)': 1,\n",
       " 'count(m)': 0,\n",
       " 'count(n)': 0,\n",
       " 'count(o)': 0,\n",
       " 'count(p)': 0,\n",
       " 'count(q)': 0,\n",
       " 'count(r)': 1,\n",
       " 'count(s)': 0,\n",
       " 'count(t)': 1,\n",
       " 'count(u)': 0,\n",
       " 'count(v)': 0,\n",
       " 'count(w)': 1,\n",
       " 'count(x)': 0,\n",
       " 'count(y)': 0,\n",
       " 'count(z)': 0,\n",
       " 'first_letter': 'w',\n",
       " 'has(a)': True,\n",
       " 'has(b)': False,\n",
       " 'has(c)': False,\n",
       " 'has(d)': False,\n",
       " 'has(e)': True,\n",
       " 'has(f)': False,\n",
       " 'has(g)': False,\n",
       " 'has(h)': False,\n",
       " 'has(i)': False,\n",
       " 'has(j)': False,\n",
       " 'has(k)': False,\n",
       " 'has(l)': True,\n",
       " 'has(m)': False,\n",
       " 'has(n)': False,\n",
       " 'has(o)': False,\n",
       " 'has(p)': False,\n",
       " 'has(q)': False,\n",
       " 'has(r)': True,\n",
       " 'has(s)': False,\n",
       " 'has(t)': True,\n",
       " 'has(u)': False,\n",
       " 'has(v)': False,\n",
       " 'has(w)': True,\n",
       " 'has(x)': False,\n",
       " 'has(y)': False,\n",
       " 'has(z)': False,\n",
       " 'last_letter': 'r'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('Walter') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627438640654499\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = train_test_split(featuresets, shuffle=True,test_size=.2)\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names, test_names = train_test_split(labeled_names, shuffle=True,test_size=.3)\n",
    "devtest_names, test_names = train_test_split(test_names, shuffle=True,test_size=.3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5560\n",
      "1589\n",
      "795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(len(s)) for s in [train_names,devtest_names,test_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602265575833858\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "     guess = classifier.classify(gender_features(name))\n",
    "     if guess != tag:\n",
    "         errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Adriaens                      \n",
      "correct=female   guess=male     name=Aigneis                       \n",
      "correct=female   guess=male     name=Alex                          \n",
      "correct=female   guess=male     name=Alexis                        \n",
      "correct=female   guess=male     name=Alis                          \n",
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Alleen                        \n",
      "correct=female   guess=male     name=Allyson                       \n",
      "correct=female   guess=male     name=Alyson                        \n",
      "correct=female   guess=male     name=Anne-Mar                      \n",
      "correct=female   guess=male     name=Ashlen                        \n",
      "correct=female   guess=male     name=Betteann                      \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Blair                         \n",
      "correct=female   guess=male     name=Bo                            \n",
      "correct=female   guess=male     name=Brear                         \n",
      "correct=female   guess=male     name=Britt                         \n",
      "correct=female   guess=male     name=Brittan                       \n",
      "correct=female   guess=male     name=Brooks                        \n",
      "correct=female   guess=male     name=Caitrin                       \n",
      "correct=female   guess=male     name=Carlynn                       \n",
      "correct=female   guess=male     name=Carmen                        \n",
      "correct=female   guess=male     name=Caro                          \n",
      "correct=female   guess=male     name=Catherin                      \n",
      "correct=female   guess=male     name=Cathrin                       \n",
      "correct=female   guess=male     name=Cathyleen                     \n",
      "correct=female   guess=male     name=Chad                          \n",
      "correct=female   guess=male     name=Charin                        \n",
      "correct=female   guess=male     name=Cher                          \n",
      "correct=female   guess=male     name=Cherin                        \n",
      "correct=female   guess=male     name=Christan                      \n",
      "correct=female   guess=male     name=Christean                     \n",
      "correct=female   guess=male     name=Christian                     \n",
      "correct=female   guess=male     name=Cindelyn                      \n",
      "correct=female   guess=male     name=Clio                          \n",
      "correct=female   guess=male     name=Cloris                        \n",
      "correct=female   guess=male     name=Colleen                       \n",
      "correct=female   guess=male     name=Darleen                       \n",
      "correct=female   guess=male     name=Deb                           \n",
      "correct=female   guess=male     name=Demeter                       \n",
      "correct=female   guess=male     name=Devan                         \n",
      "correct=female   guess=male     name=Diann                         \n",
      "correct=female   guess=male     name=Dido                          \n",
      "correct=female   guess=male     name=Doralyn                       \n",
      "correct=female   guess=male     name=Doris                         \n",
      "correct=female   guess=male     name=Dyann                         \n",
      "correct=female   guess=male     name=Ealasaid                      \n",
      "correct=female   guess=male     name=Ethelind                      \n",
      "correct=female   guess=male     name=Fern                          \n",
      "correct=female   guess=male     name=Frank                         \n",
      "correct=female   guess=male     name=Gayleen                       \n",
      "correct=female   guess=male     name=Gen                           \n",
      "correct=female   guess=male     name=Gertrudis                     \n",
      "correct=female   guess=male     name=Ginger                        \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Gunvor                        \n",
      "correct=female   guess=male     name=Gwendolen                     \n",
      "correct=female   guess=male     name=Gwendolyn                     \n",
      "correct=female   guess=male     name=Heather                       \n",
      "correct=female   guess=male     name=Hedwig                        \n",
      "correct=female   guess=male     name=Hildagard                     \n",
      "correct=female   guess=male     name=Ines                          \n",
      "correct=female   guess=male     name=Ingeberg                      \n",
      "correct=female   guess=male     name=Isabeau                       \n",
      "correct=female   guess=male     name=Jaclin                        \n",
      "correct=female   guess=male     name=Janeen                        \n",
      "correct=female   guess=male     name=Janet                         \n",
      "correct=female   guess=male     name=Janifer                       \n",
      "correct=female   guess=male     name=Janot                         \n",
      "correct=female   guess=male     name=Jerrilyn                      \n",
      "correct=female   guess=male     name=Jessalyn                      \n",
      "correct=female   guess=male     name=Jessamyn                      \n",
      "correct=female   guess=male     name=Jillian                       \n",
      "correct=female   guess=male     name=Jo Ann                        \n",
      "correct=female   guess=male     name=Jo-Ann                        \n",
      "correct=female   guess=male     name=Joannes                       \n",
      "correct=female   guess=male     name=Jojo                          \n",
      "correct=female   guess=male     name=Jonis                         \n",
      "correct=female   guess=male     name=Joscelin                      \n",
      "correct=female   guess=male     name=Joyan                         \n",
      "correct=female   guess=male     name=Juliann                       \n",
      "correct=female   guess=male     name=Kaitlyn                       \n",
      "correct=female   guess=male     name=Kameko                        \n",
      "correct=female   guess=male     name=Karleen                       \n",
      "correct=female   guess=male     name=Karmen                        \n",
      "correct=female   guess=male     name=Karon                         \n",
      "correct=female   guess=male     name=Kass                          \n",
      "correct=female   guess=male     name=Kat                           \n",
      "correct=female   guess=male     name=Katheleen                     \n",
      "correct=female   guess=male     name=Katheryn                      \n",
      "correct=female   guess=male     name=Koren                         \n",
      "correct=female   guess=male     name=Kristen                       \n",
      "correct=female   guess=male     name=Kristyn                       \n",
      "correct=female   guess=male     name=Kym                           \n",
      "correct=female   guess=male     name=Lamb                          \n",
      "correct=female   guess=male     name=Laureen                       \n",
      "correct=female   guess=male     name=Lilas                         \n",
      "correct=female   guess=male     name=Lilyan                        \n",
      "correct=female   guess=male     name=Lin                           \n",
      "correct=female   guess=male     name=Linet                         \n",
      "correct=female   guess=male     name=Loralyn                       \n",
      "correct=female   guess=male     name=Loren                         \n",
      "correct=female   guess=male     name=Lorilyn                       \n",
      "correct=female   guess=male     name=Lulu                          \n",
      "correct=female   guess=male     name=Lynett                        \n",
      "correct=female   guess=male     name=Madlen                        \n",
      "correct=female   guess=male     name=Margalit                      \n",
      "correct=female   guess=male     name=Margit                        \n",
      "correct=female   guess=male     name=Margret                       \n",
      "correct=female   guess=male     name=Mariam                        \n",
      "correct=female   guess=male     name=Marigold                      \n",
      "correct=female   guess=male     name=Maris                         \n",
      "correct=female   guess=male     name=Maryangelyn                   \n",
      "correct=female   guess=male     name=Marylin                       \n",
      "correct=female   guess=male     name=Mercedes                      \n",
      "correct=female   guess=male     name=Mignon                        \n",
      "correct=female   guess=male     name=Mildrid                       \n",
      "correct=female   guess=male     name=Miran                         \n",
      "correct=female   guess=male     name=Moreen                        \n",
      "correct=female   guess=male     name=Pen                           \n",
      "correct=female   guess=male     name=Persis                        \n",
      "correct=female   guess=male     name=Phillis                       \n",
      "correct=female   guess=male     name=Phylys                        \n",
      "correct=female   guess=male     name=Quinn                         \n",
      "correct=female   guess=male     name=Robbin                        \n",
      "correct=female   guess=male     name=Robinet                       \n",
      "correct=female   guess=male     name=Rosamund                      \n",
      "correct=female   guess=male     name=Roz                           \n",
      "correct=female   guess=male     name=Shawn                         \n",
      "correct=female   guess=male     name=Shaylyn                       \n",
      "correct=female   guess=male     name=Sioux                         \n",
      "correct=female   guess=male     name=Stoddard                      \n",
      "correct=female   guess=male     name=Suzann                        \n",
      "correct=female   guess=male     name=Thomasin                      \n",
      "correct=female   guess=male     name=Umeko                         \n",
      "correct=female   guess=male     name=Veradis                       \n",
      "correct=female   guess=male     name=Vin                           \n",
      "correct=female   guess=male     name=Vivien                        \n",
      "correct=female   guess=male     name=Wandis                        \n",
      "correct=female   guess=male     name=Wilow                         \n",
      "correct=female   guess=male     name=Wren                          \n",
      "correct=female   guess=male     name=Yehudit                       \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Abbie                         \n",
      "correct=male     guess=female   name=Alaa                          \n",
      "correct=male     guess=female   name=Ali                           \n",
      "correct=male     guess=female   name=Ambrosi                       \n",
      "correct=male     guess=female   name=Anatol                        \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Andrey                        \n",
      "correct=male     guess=female   name=Andri                         \n",
      "correct=male     guess=female   name=Angie                         \n",
      "correct=male     guess=female   name=Archy                         \n",
      "correct=male     guess=female   name=Ari                           \n",
      "correct=male     guess=female   name=Arie                          \n",
      "correct=male     guess=female   name=Barnabe                       \n",
      "correct=male     guess=female   name=Barnaby                       \n",
      "correct=male     guess=female   name=Basil                         \n",
      "correct=male     guess=female   name=Benji                         \n",
      "correct=male     guess=female   name=Benjy                         \n",
      "correct=male     guess=female   name=Berke                         \n",
      "correct=male     guess=female   name=Bill                          \n",
      "correct=male     guess=female   name=Billy                         \n",
      "correct=male     guess=female   name=Bjorne                        \n",
      "correct=male     guess=female   name=Bobby                         \n",
      "correct=male     guess=female   name=Brice                         \n",
      "correct=male     guess=female   name=Broddie                       \n",
      "correct=male     guess=female   name=Broddy                        \n",
      "correct=male     guess=female   name=Bryce                         \n",
      "correct=male     guess=female   name=Buddy                         \n",
      "correct=male     guess=female   name=Burke                         \n",
      "correct=male     guess=female   name=Burl                          \n",
      "correct=male     guess=female   name=Butch                         \n",
      "correct=male     guess=female   name=Cammy                         \n",
      "correct=male     guess=female   name=Carey                         \n",
      "correct=male     guess=female   name=Carroll                       \n",
      "correct=male     guess=female   name=Caryl                         \n",
      "correct=male     guess=female   name=Cecil                         \n",
      "correct=male     guess=female   name=Chaunce                       \n",
      "correct=male     guess=female   name=Che                           \n",
      "correct=male     guess=female   name=Chevy                         \n",
      "correct=male     guess=female   name=Christoph                     \n",
      "correct=male     guess=female   name=Churchill                     \n",
      "correct=male     guess=female   name=Clancy                        \n",
      "correct=male     guess=female   name=Claybourne                    \n",
      "correct=male     guess=female   name=Corby                         \n",
      "correct=male     guess=female   name=Costa                         \n",
      "correct=male     guess=female   name=Cy                            \n",
      "correct=male     guess=female   name=Cyril                         \n",
      "correct=male     guess=female   name=Danie                         \n",
      "correct=male     guess=female   name=Darcy                         \n",
      "correct=male     guess=female   name=Darrell                       \n",
      "correct=male     guess=female   name=Daryl                         \n",
      "correct=male     guess=female   name=Derby                         \n",
      "correct=male     guess=female   name=Deryl                         \n",
      "correct=male     guess=female   name=Donnie                        \n",
      "correct=male     guess=female   name=Douggie                       \n",
      "correct=male     guess=female   name=Doyle                         \n",
      "correct=male     guess=female   name=Duffie                        \n",
      "correct=male     guess=female   name=Dwayne                        \n",
      "correct=male     guess=female   name=Eddy                          \n",
      "correct=male     guess=female   name=Elisha                        \n",
      "correct=male     guess=female   name=Ely                           \n",
      "correct=male     guess=female   name=Emanuel                       \n",
      "correct=male     guess=female   name=Emmy                          \n",
      "correct=male     guess=female   name=Enoch                         \n",
      "correct=male     guess=female   name=Ernie                         \n",
      "correct=male     guess=female   name=Erny                          \n",
      "correct=male     guess=female   name=Errol                         \n",
      "correct=male     guess=female   name=Etienne                       \n",
      "correct=male     guess=female   name=Ezra                          \n",
      "correct=male     guess=female   name=Ferdy                         \n",
      "correct=male     guess=female   name=Freddy                        \n",
      "correct=male     guess=female   name=Gabriell                      \n",
      "correct=male     guess=female   name=Garvey                        \n",
      "correct=male     guess=female   name=Gary                          \n",
      "correct=male     guess=female   name=Gene                          \n",
      "correct=male     guess=female   name=Geoffry                       \n",
      "correct=male     guess=female   name=Gerri                         \n",
      "correct=male     guess=female   name=Godfree                       \n",
      "correct=male     guess=female   name=Goose                         \n",
      "correct=male     guess=female   name=Gordie                        \n",
      "correct=male     guess=female   name=Guthrie                       \n",
      "correct=male     guess=female   name=Guthry                        \n",
      "correct=male     guess=female   name=Hal                           \n",
      "correct=male     guess=female   name=Hamel                         \n",
      "correct=male     guess=female   name=Hamish                        \n",
      "correct=male     guess=female   name=Harley                        \n",
      "correct=male     guess=female   name=Hazel                         \n",
      "correct=male     guess=female   name=Heinrich                      \n",
      "correct=male     guess=female   name=Herbie                        \n",
      "correct=male     guess=female   name=Hodge                         \n",
      "correct=male     guess=female   name=Howie                         \n",
      "correct=male     guess=female   name=Hugh                          \n",
      "correct=male     guess=female   name=Huntlee                       \n",
      "correct=male     guess=female   name=Huntley                       \n",
      "correct=male     guess=female   name=Iggy                          \n",
      "correct=male     guess=female   name=Ignace                        \n",
      "correct=male     guess=female   name=Immanuel                      \n",
      "correct=male     guess=female   name=Isaiah                        \n",
      "correct=male     guess=female   name=Ishmael                       \n",
      "correct=male     guess=female   name=Jeffery                       \n",
      "correct=male     guess=female   name=Jereme                        \n",
      "correct=male     guess=female   name=Jesse                         \n",
      "correct=male     guess=female   name=Jimmie                        \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Joe                           \n",
      "correct=male     guess=female   name=Joel                          \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Josiah                        \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Julie                         \n",
      "correct=male     guess=female   name=Kalil                         \n",
      "correct=male     guess=female   name=Kane                          \n",
      "correct=male     guess=female   name=Karel                         \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Kennedy                       \n",
      "correct=male     guess=female   name=Lance                         \n",
      "correct=male     guess=female   name=Larry                         \n",
      "correct=male     guess=female   name=Laurie                        \n",
      "correct=male     guess=female   name=Lawerence                     \n",
      "correct=male     guess=female   name=Lefty                         \n",
      "correct=male     guess=female   name=Lemuel                        \n",
      "correct=male     guess=female   name=Locke                         \n",
      "correct=male     guess=female   name=Lorrie                        \n",
      "correct=male     guess=female   name=Marchall                      \n",
      "correct=male     guess=female   name=Marmaduke                     \n",
      "correct=male     guess=female   name=Marsh                         \n",
      "correct=male     guess=female   name=Martie                        \n",
      "correct=male     guess=female   name=Mattie                        \n",
      "correct=male     guess=female   name=Maurice                       \n",
      "correct=male     guess=female   name=Maurie                        \n",
      "correct=male     guess=female   name=Maury                         \n",
      "correct=male     guess=female   name=Maxwell                       \n",
      "correct=male     guess=female   name=Meredeth                      \n",
      "correct=male     guess=female   name=Meredith                      \n",
      "correct=male     guess=female   name=Michal                        \n",
      "correct=male     guess=female   name=Michale                       \n",
      "correct=male     guess=female   name=Micheal                       \n",
      "correct=male     guess=female   name=Michel                        \n",
      "correct=male     guess=female   name=Mickie                        \n",
      "correct=male     guess=female   name=Mikhail                       \n",
      "correct=male     guess=female   name=Mischa                        \n",
      "correct=male     guess=female   name=Morlee                        \n",
      "correct=male     guess=female   name=Mortie                        \n",
      "correct=male     guess=female   name=Murphy                        \n",
      "correct=male     guess=female   name=Neal                          \n",
      "correct=male     guess=female   name=Nealy                         \n",
      "correct=male     guess=female   name=Nicky                         \n",
      "correct=male     guess=female   name=Nikita                        \n",
      "correct=male     guess=female   name=Nikki                         \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Paddy                         \n",
      "correct=male     guess=female   name=Parke                         \n",
      "correct=male     guess=female   name=Pattie                        \n",
      "correct=male     guess=female   name=Paul                          \n",
      "correct=male     guess=female   name=Pavel                         \n",
      "correct=male     guess=female   name=Percy                         \n",
      "correct=male     guess=female   name=Petey                         \n",
      "correct=male     guess=female   name=Prentice                      \n",
      "correct=male     guess=female   name=Quill                         \n",
      "correct=male     guess=female   name=Ramesh                        \n",
      "correct=male     guess=female   name=Ramsay                        \n",
      "correct=male     guess=female   name=Randal                        \n",
      "correct=male     guess=female   name=Randie                        \n",
      "correct=male     guess=female   name=Randy                         \n",
      "correct=male     guess=female   name=Ransell                       \n",
      "correct=male     guess=female   name=Ravil                         \n",
      "correct=male     guess=female   name=Reggy                         \n",
      "correct=male     guess=female   name=Richie                        \n",
      "correct=male     guess=female   name=Rickey                        \n",
      "correct=male     guess=female   name=Ricki                         \n",
      "correct=male     guess=female   name=Rickie                        \n",
      "correct=male     guess=female   name=Rikki                         \n",
      "correct=male     guess=female   name=Rocky                         \n",
      "correct=male     guess=female   name=Roddy                         \n",
      "correct=male     guess=female   name=Roderich                      \n",
      "correct=male     guess=female   name=Rodge                         \n",
      "correct=male     guess=female   name=Rodney                        \n",
      "correct=male     guess=female   name=Rodolphe                      \n",
      "correct=male     guess=female   name=Ronnie                        \n",
      "correct=male     guess=female   name=Royce                         \n",
      "correct=male     guess=female   name=Ruddy                         \n",
      "correct=male     guess=female   name=Rufe                          \n",
      "correct=male     guess=female   name=Sal                           \n",
      "correct=male     guess=female   name=Sammie                        \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Sansone                       \n",
      "correct=male     guess=female   name=Sasha                         \n",
      "correct=male     guess=female   name=Saul                          \n",
      "correct=male     guess=female   name=Say                           \n",
      "correct=male     guess=female   name=Scotty                        \n",
      "correct=male     guess=female   name=Selby                         \n",
      "correct=male     guess=female   name=Seth                          \n",
      "correct=male     guess=female   name=Sheffy                        \n",
      "correct=male     guess=female   name=Smith                         \n",
      "correct=male     guess=female   name=Solly                         \n",
      "correct=male     guess=female   name=Stanleigh                     \n",
      "correct=male     guess=female   name=Stevy                         \n",
      "correct=male     guess=female   name=Tabbie                        \n",
      "correct=male     guess=female   name=Tabby                         \n",
      "correct=male     guess=female   name=Tanny                         \n",
      "correct=male     guess=female   name=Terri                         \n",
      "correct=male     guess=female   name=Terrill                       \n",
      "correct=male     guess=female   name=Terry                         \n",
      "correct=male     guess=female   name=Thatch                        \n",
      "correct=male     guess=female   name=Thayne                        \n",
      "correct=male     guess=female   name=Thorndike                     \n",
      "correct=male     guess=female   name=Thorpe                        \n",
      "correct=male     guess=female   name=Timothy                       \n",
      "correct=male     guess=female   name=Tobie                         \n",
      "correct=male     guess=female   name=Toddy                         \n",
      "correct=male     guess=female   name=Tonnie                        \n",
      "correct=male     guess=female   name=Tre                           \n",
      "correct=male     guess=female   name=Tremaine                      \n",
      "correct=male     guess=female   name=Tucky                         \n",
      "correct=male     guess=female   name=Ty                            \n",
      "correct=male     guess=female   name=Uri                           \n",
      "correct=male     guess=female   name=Uriah                         \n",
      "correct=male     guess=female   name=Vassily                       \n",
      "correct=male     guess=female   name=Verney                        \n",
      "correct=male     guess=female   name=Virgil                        \n",
      "correct=male     guess=female   name=Vite                          \n",
      "correct=male     guess=female   name=Wade                          \n",
      "correct=male     guess=female   name=Wadsworth                     \n",
      "correct=male     guess=female   name=Warde                         \n",
      "correct=male     guess=female   name=Welby                         \n",
      "correct=male     guess=female   name=Welch                         \n",
      "correct=male     guess=female   name=Wendel                        \n",
      "correct=male     guess=female   name=Wendell                       \n",
      "correct=male     guess=female   name=Weslie                        \n",
      "correct=male     guess=female   name=Westley                       \n",
      "correct=male     guess=female   name=Wiley                         \n",
      "correct=male     guess=female   name=Willey                        \n",
      "correct=male     guess=female   name=Willi                         \n",
      "correct=male     guess=female   name=Wittie                        \n",
      "correct=male     guess=female   name=Woodie                        \n",
      "correct=male     guess=female   name=Zebedee                       \n",
      "correct=male     guess=female   name=Zechariah                     \n",
      "correct=male     guess=female   name=Zedekiah                      \n",
      "correct=male     guess=female   name=Zippy                         \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "     print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "     return {'suffix1': word[-1:],\n",
    "             'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853996224040277\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))\n",
    "#we need more on feature selection, chisquare etc...accuracy chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3   Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = train_test_split(featuresets, shuffle=True,test_size=.2)\n",
    "# train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6725\n",
      "Most Informative Features\n",
      "        contains(hudson) = True              neg : pos    =      7.8 : 1.0\n",
      "            contains(et) = True              pos : neg    =      7.6 : 1.0\n",
      "          contains(taxi) = True              pos : neg    =      7.6 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =      7.4 : 1.0\n",
      "        contains(debate) = True              pos : neg    =      7.3 : 1.0\n",
      "           contains(ivy) = True              neg : pos    =      6.4 : 1.0\n",
      "  contains(confidential) = True              pos : neg    =      6.3 : 1.0\n",
      "         contains(whore) = True              neg : pos    =      5.7 : 1.0\n",
      "          contains(lang) = True              pos : neg    =      5.6 : 1.0\n",
      "        contains(freely) = True              pos : neg    =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4   Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "     word = word.lower()\n",
    "     suffix_fdist[word[-1:]] += 1\n",
    "     suffix_fdist[word[-2:]] += 1\n",
    "     suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "     features = {}\n",
    "     for suffix in common_suffixes:\n",
    "         features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-12cc5a8dda35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# size = int(len(featuresets) * 0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# train_set, test_set = featuresets[size:], featuresets[:size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# size = int(len(featuresets) * 0.1)\n",
    "# train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "train_set, test_set = train_test_split(featuresets, shuffle=False,test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-0c836654950f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Refine the stump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tree.refine(labeled_featuresets, entropy_cutoff, depth_cutoff-1,\n\u001b[0;32m--> 161\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[1;32m    202\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_cutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     support_cutoff, binary, feature_values, verbose)\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             default_featuresets = [(featureset, label) for (featureset, label)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             tree = DecisionTreeClassifier.best_stump(\n\u001b[0;32m--> 154\u001b[0;31m                 feature_names, labeled_featuresets, verbose)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             tree = DecisionTreeClassifier.best_binary_stump(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mbest_stump\u001b[0;34m(feature_names, labeled_featuresets, verbose)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mbest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_stump\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mstump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mstump_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstump\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstump_error\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/classify/decisiontree.py\u001b[0m in \u001b[0;36mstump\u001b[0;34m(feature_name, labeled_featuresets)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         label = FreqDist(label for (featureset, label)\n\u001b[0;32m--> 175\u001b[0;31m                          in labeled_featuresets).max()\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Find the best label for each value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mCounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Cached number of samples in this FreqDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/probability.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(pos_features('dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: \n",
      "      if endswith(.) == False: return 'NP-HL'\n",
      "      if endswith(.) == True: return '.'\n",
      "    if endswith(s) == True: \n",
      "      if endswith(was) == False: return 'NNS'\n",
      "      if endswith(was) == True: return 'BEDZ'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.pseudocode(depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5   Exploiting Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "     untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "     for i, (word, tag) in enumerate(tagged_sent):\n",
    "         featuresets.append( (pos_features(untagged_sent, i), tag) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7771479713603818"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size = int(len(featuresets) * 0.1)\n",
    "# train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "train_set, test_set = train_test_split(featuresets, shuffle=False,test_size=.1)\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "     features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "     if i == 0:\n",
    "         features[\"prev-word\"] = \"<START>\"\n",
    "         features[\"prev-tag\"] = \"<START>\"\n",
    "     else:\n",
    "         features[\"prev-word\"] = sentence[i-1]\n",
    "         features[\"prev-tag\"] = history[i-1]\n",
    "     return features\n",
    "\n",
    "class ConsecutivePosTagger(nltk.TaggerI): \n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7870028904614771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79796012981"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "# size = int(len(tagged_sents) * 0.1)\n",
    "# train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "train_sents, test_sents = train_test_split(tagged_sents, shuffle=False,test_size=.1)\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(tagger.evaluate(test_sents))\n",
    "0.79796012981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
